#### 웹 데이터 수집(크롤링)
- 서버에서 문저 요청 후 응답되는 정보를 변수에 저장(문자열)
  1. 관련 패키지 : `urllib`, `requests`
  2. 접속 후 응답 : `urllib.urlopen('서버주소')`, `request.get('서버주소')`
  3. `read()로 코드 읽어오기(html)`
- 저장된 변수에서 원하는 내용 추출(파싱)
  1. `parsing` : 문자열에서 패턴을 찾아 원하는 정보를 추출하는 과정
  2. 관련 패키지 : `BeautifulSoup` 패키지 / `find()` 함수
- 상태 코드 
  1. 200 은 정상응답
  2. 400 번대 코드 : 클라이언트의 요청이 잘못되었다는 의미(url주소가 틀렸거나 권한이 없는 페이지를 요청했거나...)
  3. 500 번대 코드 : 클라이언트는 문법에 맞게 요청을 했는데 서버측에서 인증이 안되었거나, 서버가 오류가 있는 상태
- 주의 사항
  1. 정적사이트가 동적사이트가 되기도 하고 속성값이 변경되기도 한다.

#### BeautifulSoup 패키지 파싱 함수
- `find(태그, [{속성명:속성값}])` : 지정한 태그 중 첫번째 만나는 태그만 추출
- `findAll(태그, [{속성명:속성값}])` : 지정한 태그 모두 추출 / `list` 형태로 반환
- `find_all(태그, [{속성명:속성값}])` : `findAll()` 과 같은 함수
- 형제노드 찾기 : `find()` 찾고 `next_sibling` -> 이용 다음 형제노드를 추출
- `bs4.select(태그)` : 태그나 속성을 이용해서 지칭하는 `selector` 기능을 사용해서 추출
  1. 기호 : `class(.)`, `id(#)`, `자식태그(>)`, `자손태그(공백)`

