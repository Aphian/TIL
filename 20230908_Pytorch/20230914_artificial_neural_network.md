### 인공 신경망 (Aritificial Neural Network)

#### 머신 러닝 용어
- 머신 러닝 모델의 평가
  - 전체 데이터 (훈련`(Training)` / 테스트`(Testing)`)
  - 전체 데이터 (훈련`(Training)` / 검증`(Vaildation)` / 테스트 `(Testing)`)
  - 검증 데이터 : 모델의 성능을 조정하기 위한 용도 / 하이퍼파라미터 값을 조정하는 용도 / 사용자가 직접 정해줄 수 있음
  - 모델 성능에 영향을 주는 변수 : 매개변수 / 기계가 훈련을 통해서 바꾸는 변수
- 선형 회귀 : 학습률이 하이퍼파라미터에 해당
- 딥러닝 : 은닉층의 수, 뉴런의 수, 드롭아웃 비율

#### 분류 / 회귀
- 머신 러닝 기법 선형 회귀 / 로지스틱 회귀(분류)
  - 분류 : 이진 분류 / 다중 클래스 분류
    - 이진 분류 : 입력에 대해서 둘 중 하나의 답을 정하는 문제
    - 다중 분류 : 입력에 대해서 세 개 이상의 정해진 선택지 중 답을 정하는 문제
  - 회귀 : 연속된 값을 결과로 가짐 
    - ex. 시계열 데이터, 시험 성적

#### 지도 학습 / 비지도 학습 / 강화 학습
- 지도 학습 : `Label` 이라는 정답과 함께 학습하는 것
  - 기계는 예측값과 실제값의 오차를 줄이는 방식
- 비지도 학습 : 목적 데이터가 없는 학습 방법 / 군집`(Clustering)`
- 강화 학습 : 어떤 환경 내에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화 하는 행동 혹은 순서를 선택하는 방법

#### 샘플 / 특성
- 머신 러닝에서의 하나의 데이터, 하나의 행을 샘플`(Sample)`
- 종속변수를 예측하기 위한 각각의 독립 변수를 특성`(feature)`

#### 혼동 행렬
- 맞춘 문제수 / 전체 문제수 : 정확도`(Accuracy)`
  - 세부적인 애용을 알려주진 않은데 이를 위해 사용하는 것이 혼동 행렬

#### 과적합 / 과소적합
- 과적합 : 훈련 데이터를 과하게 학습한 경우
  - -> 테스트 데이터나 실제 서비스에서의 데이터에 대해서는 정확도가 좋지 않은 현상
  - 훈련 데이터에 대해서는 오차가 낮지만, 테스트 데이터에 대해서는 오차가 높아지는 상황
  - 보완 방법
    - 데이터의 양 증가
    - 모델의 복잡도 줄이기
    - 가중치 규제
    - 드롭아웃
- 과소 작합 : 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태
  - 훈련 자체가 부족한 상태이므로 과대 적합과는 달리 훈련 데이터에 대해서도 보통 정확도가 낮다는 특징

#### 퍼셉트론
- 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘
- 뉴런에서의 출력값을 변경시키는 합수를 활성화 함수
  - 시그모이드 함수
  - 소프트맥스 함수
- 단층 퍼셉트론 : 입력층 / 출력층 두 단계로만 이뤄짐, 단계를 `layer`라고 부름
- 다층 퍼셉트론 : 입력층과 출력층 사이에 은닉층이 존재함
  - 은닉층이 2개 이상인 경우 **심층 심경망**이라도 함
- 가중치를 자동으로 찾도록 하는데 머신러닝에서 학습`(training)`단계
- 인공 신경망이 심층 신경망일 경우 딥러닝이라고 한다.

#### 비선형 활성화 함수
- 입력을 받아 수학적 변환을 수행하고 출력을 생성하는 함수
- 시그모이드 함수 / 소프트 맥스 함수
- 하이퍼볼릭탄젠트 함수 : 입력값을 `-1과 1` 사이의 값으로 변환
- 렐루 함수
  - 렐루 함수는 음수를 입력하면 `0`을 출력하고, 양수를 입력하면 입력값을 그대로 반환합니다. 
  - 렐루 함수는 특정 양수값에 수렴하지 않으므로 깊은 신경망에서 시그모이드 함수보다 훨씬 더 잘 작동한다.
  - 연산이 필요한 것이 아니라 단순 임계값으로 연산인 빠름
- 시그모이드 함수 : 이진 분류에서 활용
- 소프트맥스 함수 : 다중 클래스 분류