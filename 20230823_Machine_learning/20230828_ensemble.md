### 앙상블 학습
- 여러 개의 분류기를 사용해서 예측 결합함으로써 보다 정확한 최종 예측 도출
- 정형 데이터 분류 시 뛰어난 성능
- 이미지, 영상, 음성 등의 비정형 데이터 분류 : 딥러닝 성능에서 뛰어남

#### 앙상블 알고리즘
- 랜덤포레스트
- 그래디언트 부스팅
- `XGBoost`
- `LightBGM` : `XGBoost` 예측 성능과 유사하면서 수행속도가 훨씬 빠름
- `Stacking` : 메타모델 수립

#### 앙상블 결합 방법
- `보팅(Voting)` : 여러 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식
  - 서로 다른 알고리즘을 가진 분류기 결합
- `배깅(Bagging)` : 보팅과 동일하게 여러 분류기가 투표를 통해 최종 예측 결과를 결정
  - 각각의 분류기가 같은 유형의 알고리즘 기반
  - 샘플링을 서로 다르게 하면서 학습 수행
  - 대표적인 배깅 방식 : 랜덤 포레스트 알고리즘
- 샘플링 방식
  - 개별 분류기에서 데이터를 샘플링해서 추출하는 방식
  - 각 샘플링된 데이터 내에는 중복 데이터 포함
- `부스팅(Boosting)` : 여러 개의 분류기가 순차적으로 학습 수행하되 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서는 올바르게 예측할 수 있도록 다음 분류기에게는 **가중치(weight)를 부여**하면서 학습과 예측을 진행하는 방식
  - 대표적 모듈 
    1. `Gradient Boost`
    2. `XGBoost` : 병렬처리 가능
    3. `LightGBM` : 성능도 많이 좋아지고 속도도 빨라짐, 많은양의 데이터 최적의 성능, 단, 관측치가 10,000 이하면 효율적이지 못하다고 발표하고 있음

#### 보팅(Voting) 유형
- 하드보팅 : 다수결 원칙과 유사
- 소프트보팅 : 분류기들의 레이블 값 결정 확률을 평균내서 확률이 가장 높은 레이블 값을 최종 보팅 결과값으로 선정, 일반적으로 소프트보팅이 예측 성능이 좋아 많이 사용

#### 배깅(Bagging) 유형
- 기반 알고리즘 : 의사결정 트리(약한 모델임)
  - 결정트리 모델 : 쉽고 직관적인 분류 기준 / 데이터를 과하게 학습-과적합
- 대표적 알고리즘 : 랜덤포레스트 알고리즘(수행속도가 빠름 / 데이터 양이 많으면 급속도로 느려지는 현상)
  